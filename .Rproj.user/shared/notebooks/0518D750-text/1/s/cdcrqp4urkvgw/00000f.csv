"0",""
"0","# Comienzo el proceso de transformación desde cuanti_palabras a cuanti_palabras_ok"
"0","# Se sacan los puntos"
"0","# Se pasa todo a minúscula. Es importante porque el stemming y las stopword funcionan mejor"
"0","# Se sacan las stopwords"
"0","# Se hace el stemming"
"0","# Se sacan los acentos. Esto va a lo último porque modifica el stemming."
"0",""
"0","# Se sacan las ""s"""
"0","# Se sacan las stopword (quanteda tiene uno bueno pero primera hay que token)"
"0","# Tidytext tiene un wraping para la funcion stopword del paquete stopwords"
"0","# El proceso de stemming lo hago con hunspell en vez de que con snowball. "
"0","# "
"0","# Cambio a mano el diccionario de hunspell y luego lo especifico en el código"
"0",""
"0","# Creo in objeto con los stopword. Uso tidytext para hacer un antijoint pero la base de datos"
"0","# sale del paquete stopwords que, a su turno, levanta base de distintos lugares."
"0","# El stopword lo uso luego de poner las palabras en minúsculas"
"0",""
"0","cuanti_stopwords <- get_stopwords(language = ""es"", source = ""nltk"") |> # Por ahora nltk tiene más palabras"
"0","                    rename(cuanti_stopwords = word)"
"0",""
"0","df_longer <- df_longer |>"
"0","mutate("
"0","cuanti_palabras_ok = str_replace(cuanti_palabras, ""[.]+$"", """"), # Saco los puntos"
"0","cuanti_palabras_ok = str_to_lower(cuanti_palabras_ok)) # Todo a minuscula"
"0",""
"0","df_longer <- df_longer |> "
"0","anti_join(cuanti_stopwords, by = c(""cuanti_palabras_ok"" = ""cuanti_stopwords"")) # Stopwords"
"0",""
"0","# Antes del stemming pruebo con el corrector de palabras"
"0","# "
"0","# Si previamente el (nuevo) diccionario ya está creado se buscar como un nuevo lenguaje de diccionario"
"0","# Me sirve para stemming"
"0",""
"0","cuanti_diccionario <- hunspell::dictionary(lang = ""es_ES_delta"")"
"0",""
"0","df_longer <- df_longer |>"
"0","mutate("
"0","cuanti_palabras_analyze = hunspell_analyze(cuanti_palabras_ok, cuanti_diccionario),"
"0","cuanti_palabras_check = hunspell_check(cuanti_palabras_ok, cuanti_diccionario),"
"0","cuanti_palabras_suggest = hunspell_suggest(cuanti_palabras_ok, cuanti_diccionario))"
"0",""
"0","# La idea es la siguiente:"
"0","# Si el check dió false, va la (única) palabra que salió en suggest."
"0","# Si el check dió true, va la primera palabra de la lista"
"0",""
"0","#df_longer$cuanti_palabras_suggest #df_longer$cuanti_palabras_suggest[sapply(length(df_longer$cuanti_palabras_suggest == 0))] #if_else(df_longer$cuanti_palabras_suggest[sapply(length(df_longer$cuanti_palabras_suggest == 0))],"
"0","         #                                   NA,"
"0","#                                            cuanti_palabras_suggest)"
"0",""
"0","df_longer <- df_longer |>"
"0","mutate(cuanti_palabras_pre_stem = map(cuanti_palabras_suggest,1))"
"0",""
"0","df_longer$cuanti_palabras_pre_stem[sapply(df_longer$cuanti_palabras_pre_stem, is.null)] <- NA"
"0",""
"0","df_longer <- df_longer |>"
"0","mutate(cuanti_palabras_pre_stem = unlist(cuanti_palabras_pre_stem))"
"0",""
"0","# Stemming"
"0","# Así como para las stopwords hice un archivo específico ahora hago un"
"0","# diccionario que agrega más palabras al original"
"0","# Hay que tener cuidado porque ""quanteda"" pisa a dictionary de ""hunspell"""
"0",""
"0","df_longer <- df_longer |>"
"0","mutate(cuanti_palabras_stem = hunspell_stem(cuanti_palabras_pre_stem, dict = cuanti_diccionario))"
"0",""
"0","df_longer <- df_longer |>"
"0","mutate(cuanti_palabras_stem = map(cuanti_palabras_stem,1))"
"0",""
"0","df_longer$cuanti_palabras_stem[sapply(df_longer$cuanti_palabras_stem, is.null)] <- NA"
"0",""
"0","df_longer <- df_longer |>"
"0","mutate(cuanti_palabras_stem = unlist(cuanti_palabras_stem))"
"0",""
"0","# Arreglo a mano algunos pequeños casos"
"0",""
"0","df_longer <-  df_longer |>"
"0","mutate("
"0","cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, ""métodos"", ""método""),"
"0","cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, ""cantidades"", ""cantidad""),"
"0","cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, ""estadísticas"", ""estadística""),"
"0","cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, ""encuestas"", ""encuesta""),"
"0","cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, ""técnicas"", ""técnica""),"
"0","cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, ""porcentajes"", ""porcentaje""),"
"0","cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, ""cuentas"", ""contar""))      "
"0",""
"0","          "
"0","#cuanti_palabras_ok = stringi::stri_trans_general(cuanti_palabras_ok, ""Latin-ASCII"")), # Saco los acentos"
"0",""
"0","#df_longer <- df_longer |>"
"0","#mutate("
"0","#cuanti_palabras_hunspell = hunspell_stem(cuanti_palabras_ok, dict = cuanti_diccionario))"
"0",""
"0",""
"0","#cuanti_palabras_snowballc = wordStem(cuanti_palabras, language = ""spanish""))"
"0",""
"0","#cuanti_palabras_hunspell_check = hunspell_check(cuanti_palabras, dict = dictionary(""es_ES"")),"
