here("Outputs","df_encuesta.rds"))
library(tidygraph)
library(ggraph)
library(stringr)
library(tidyverse)
library(here)
# Levanto el dataset de la encuesta
# Pongo "redes_tu_nombre"como primera columna
df_encuesta <- read_rds(here::here("Outputs", "df_encuesta.rds")) |>
relocate(redes_tu_nombre)
nodes <- df_encuesta
# Hay que realizar desde el archivo de la encuesta dos columnas (from, to) en donde
# el "from" sea el encuestado "redes_tun_nombre" y que el "to" sea el estudiante a quien haya
# elegido. Dado que cada encuestado elige a 5 estudiantes en este nuevo objeto debería
# haber 5 filas por encuestado.
# Luego de eso se debería filtrar "los edges" para que queden sólo aquellos que están presentes
# en el "nodes", esto es, con los que contestaron la encuesta.
#
# Se podría agregar otras columnas al edge
#       cuanti_comision,
#                       unaj_ano_ingreso,
#                       unaj_n_materias_aprobadas,
#                       unaj_n_materias_aprobadas_10
edges <- df_encuesta |>
select(mail,
redes_tu_nombre,
redes_1_contacto,
redes_2_contacto,
redes_3_contacto,
redes_4_contacto,
redes_5_contacto,
cuanti_docente,
unaj_ano_ingreso,
unaj_n_materias_aprobadas,
unaj_n_materias_aprobadas_10) |>
pivot_longer(c(
redes_1_contacto,
redes_2_contacto,
redes_3_contacto,
redes_4_contacto,
redes_5_contacto),
names_to = "orden_del_contacto",
values_to = "to") |>
mutate(intensidad_relacion = as.integer(case_when(orden_del_contacto == "redes_1_contacto" ~ "1",
orden_del_contacto == "redes_2_contacto" ~ "2",
orden_del_contacto == "redes_3_contacto" ~ "3",
orden_del_contacto == "redes_4_contacto" ~ "4",
orden_del_contacto == "redes_5_contacto" ~ "5"))) |>
select(!c(mail, orden_del_contacto)) |>
semi_join(nodes, by = c("to" = "redes_tu_nombre")) |>
rename(from = redes_tu_nombre) |>
relocate(to)
# Creo la red
red <- tbl_graph(nodes = nodes,
node_key = "redes_tu_nombre",
edges = edges,
directed = TRUE)
# se puede agregar "directed = TRUE" pero algunas medidas de comunidad no se pueden calcular
red_diego <- red |>
activate(nodes) |>
filter(cuanti_docente == "Diego Quartulli") |>
filter(!is.na(unaj_n_materias_aprobadas_10)) |>
mutate(pagerank = centrality_pagerank(),
siglas = str_sub(redes_tu_nombre, start = 1L, end = 5L),
comunidad = as.factor(group_components())) |>
activate(edges) |>
mutate(intermediacion = centrality_edge_betweenness())
grafo_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = intermediacion)) +
geom_node_point(aes(size = pagerank, colour = pagerank)) +
scale_color_continuous(guide = 'legend') +
theme_graph()
grafo_diego
ggsave(here("Outputs", "grafo_diego.png"))
# En este link hay varias buenas opciones de gráficos
# http://users.dimi.uniud.it/~massimo.franceschet/ns/syllabus/make/tidygraph/tidygraph.html
nodos <- red_diego |>
activate(nodes) |>
as_tibble()
comunidad_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = stat(index)), show.legend = FALSE) +
geom_node_point(aes(colour = comunidad), size = 5) +
geom_node_text(aes(label = siglas), repel = TRUE)
theme_graph()
comunidad_diego
comunidad_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = stat(index)), show.legend = FALSE) +
geom_node_point(aes(colour = comunidad), size = 5) +
geom_node_text(aes(label = siglas), repel = TRUE)
theme_graph()
comunidad_diego
comunidad_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = stat(index)), show.legend = FALSE) +
geom_node_point(aes(colour = comunidad), size = 5) +
geom_node_text(aes(label = siglas), repel = TRUE)
theme_graph()
comunidad_diego
comunidad_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = stat(index)), show.legend = FALSE) +
geom_node_point(aes(colour = comunidad), size = 5) +
geom_node_text(aes(label = siglas), repel = TRUE)
theme_graph(foreground = 'steelblue', fg_text_colour = 'white', base_family = 'Helvetica'))
comunidad_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = stat(index)), show.legend = FALSE) +
geom_node_point(aes(colour = comunidad), size = 5) +
geom_node_text(aes(label = siglas), repel = TRUE)
theme_graph(foreground = 'steelblue', fg_text_colour = 'white', base_family = 'Helvetica')
comunidad_diego
install.packages("styler")
#| echo: false
#| output: false
grafo_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = intermediacion)) +
geom_node_point(aes(size = pagerank, colour = pagerank)) +
scale_color_continuous(guide = 'legend') +
theme_graph()
library(tidygraph)
library(ggraph)
library(stringr)
library(tidyverse)
library(here)
#| echo: false
#| output: false
grafo_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = intermediacion)) +
geom_node_point(aes(size = pagerank, colour = pagerank)) +
scale_color_continuous(guide = 'legend') +
theme_graph()
red_diego <- red |>
activate(nodes) |>
filter(cuanti_docente == "Diego Quartulli") |>
filter(!is.na(unaj_n_materias_aprobadas_10)) |>
mutate(pagerank = centrality_pagerank(),
siglas = str_sub(redes_tu_nombre, start = 1L, end = 5L),
comunidad = as.factor(group_components())) |>
activate(edges) |>
mutate(intermediacion = centrality_edge_betweenness())
library(tidygraph)
library(ggraph)
library(stringr)
library(tidyverse)
library(here)
# Levanto el dataset de la encuesta
# Pongo "redes_tu_nombre"como primera columna
df_encuesta <- read_rds(here::here("Outputs", "df_encuesta.rds")) |>
relocate(redes_tu_nombre)
nodes <- df_encuesta
# Hay que realizar desde el archivo de la encuesta dos columnas (from, to) en donde
# el "from" sea el encuestado "redes_tun_nombre" y que el "to" sea el estudiante a quien haya
# elegido. Dado que cada encuestado elige a 5 estudiantes en este nuevo objeto debería
# haber 5 filas por encuestado.
# Luego de eso se debería filtrar "los edges" para que queden sólo aquellos que están presentes
# en el "nodes", esto es, con los que contestaron la encuesta.
#
# Se podría agregar otras columnas al edge
#       cuanti_comision,
#                       unaj_ano_ingreso,
#                       unaj_n_materias_aprobadas,
#                       unaj_n_materias_aprobadas_10
edges <- df_encuesta |>
select(mail,
redes_tu_nombre,
redes_1_contacto,
redes_2_contacto,
redes_3_contacto,
redes_4_contacto,
redes_5_contacto,
cuanti_docente,
unaj_ano_ingreso,
unaj_n_materias_aprobadas,
unaj_n_materias_aprobadas_10) |>
pivot_longer(c(
redes_1_contacto,
redes_2_contacto,
redes_3_contacto,
redes_4_contacto,
redes_5_contacto),
names_to = "orden_del_contacto",
values_to = "to") |>
mutate(intensidad_relacion = as.integer(case_when(orden_del_contacto == "redes_1_contacto" ~ "1",
orden_del_contacto == "redes_2_contacto" ~ "2",
orden_del_contacto == "redes_3_contacto" ~ "3",
orden_del_contacto == "redes_4_contacto" ~ "4",
orden_del_contacto == "redes_5_contacto" ~ "5"))) |>
select(!c(mail, orden_del_contacto)) |>
semi_join(nodes, by = c("to" = "redes_tu_nombre")) |>
rename(from = redes_tu_nombre) |>
relocate(to)
# Creo la red
red <- tbl_graph(nodes = nodes,
node_key = "redes_tu_nombre",
edges = edges,
directed = TRUE)
# se puede agregar "directed = TRUE" pero algunas medidas de comunidad no se pueden calcular
red_diego <- red |>
activate(nodes) |>
filter(cuanti_docente == "Diego Quartulli") |>
filter(!is.na(unaj_n_materias_aprobadas_10)) |>
mutate(pagerank = centrality_pagerank(),
siglas = str_sub(redes_tu_nombre, start = 1L, end = 5L),
comunidad = as.factor(group_components())) |>
activate(edges) |>
mutate(intermediacion = centrality_edge_betweenness())
#| echo: false
#| output: false
grafo_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = intermediacion)) +
geom_node_point(aes(size = pagerank, colour = pagerank)) +
scale_color_continuous(guide = 'legend') +
theme_graph()
grafo_diego
ggsave(here("Outputs", "grafo_diego.png"))
# En este link hay varias buenas opciones de gráficos
# http://users.dimi.uniud.it/~massimo.franceschet/ns/syllabus/make/tidygraph/tidygraph.html
#| echo: false
#| output: true
library(dplyr)
library(gt)
conteo_palabras_general <- df_longer |>
filter(!is.na(cuanti_palabras_pre_stem)) |>
count(cuanti_palabras_pre_stem) |>
arrange(desc(n)) |>
filter(n > 1) |>
mutate(Porcentaje = n/sum(n))
# Levanto el dataset de la encuesta
library(stringr)
library(tidytext)
library(hunspell) # Funciona mejor para el español. Uso la versión de desarrollo porque
# funciona mejor los diccionario en rstudio
#devtools::install_github("ropensci/hunspell", force = TRUE)
library(purrr)
library(tidyverse)
# Levanto el dataset de la encuesta
df_encuesta <- read_rds(here::here("Outputs", "df_encuesta.rds"))
df_longer <- df_encuesta |>
select(dni,
unaj_ano_ingreso,
unaj_n_materias_aprobadas_10,
unaj_n_materias_aprobadas_15,
sexo,
hog_convivencia_hijes,
cuanti_1_palabra,
cuanti_2_palabra,
cuanti_3_palabra) |>
pivot_longer(c(cuanti_1_palabra,
cuanti_2_palabra,
cuanti_3_palabra),
names_to = "orden_palabra",
values_to = "cuanti_palabras")
# Comienzo el proceso de transformación desde cuanti_palabras a cuanti_palabras_ok
# Se sacan los puntos
# Se pasa todo a minúscula. Es importante porque el stemming y las stopword funcionan mejor
# Se sacan las stopwords
# Se hace el stemming
# Se sacan los acentos. Esto va a lo último porque modifica el stemming.
# Se sacan las "s"
# Se sacan las stopword (quanteda tiene uno bueno pero primera hay que token)
# Tidytext tiene un wraping para la funcion stopword del paquete stopwords
# El proceso de stemming lo hago con hunspell en vez de que con snowball.
#
# Cambio a mano el diccionario de hunspell y luego lo especifico en el código
# Creo in objeto con los stopword. Uso tidytext para hacer un antijoint pero la base de datos
# sale del paquete stopwords que, a su turno, levanta base de distintos lugares.
# El stopword lo uso luego de poner las palabras en minúsculas
cuanti_stopwords <- get_stopwords(language = "es", source = "nltk") |> # Por ahora nltk tiene más palabras
rename(cuanti_stopwords = word)
df_longer <- df_longer |>
mutate(
cuanti_palabras_ok = str_replace(cuanti_palabras, "[.]+$", ""), # Saco los puntos
cuanti_palabras_ok = str_to_lower(cuanti_palabras_ok)) # Todo a minuscula
df_longer <- df_longer |>
anti_join(cuanti_stopwords, by = c("cuanti_palabras_ok" = "cuanti_stopwords")) # Stopwords
# Antes del stemming pruebo con el corrector de palabras
#
# Si previamente el (nuevo) diccionario ya está creado se buscar como un nuevo lenguaje de diccionario
# Me sirve para stemming
cuanti_diccionario <- hunspell::dictionary(lang = "es_ES_delta")
df_longer <- df_longer |>
mutate(
cuanti_palabras_analyze = hunspell_analyze(cuanti_palabras_ok, cuanti_diccionario),
cuanti_palabras_check = hunspell_check(cuanti_palabras_ok, cuanti_diccionario),
cuanti_palabras_suggest = hunspell_suggest(cuanti_palabras_ok, cuanti_diccionario))
# La idea es la siguiente:
# Si el check dió false, va la (única) palabra que salió en suggest.
# Si el check dió true, va la primera palabra de la lista
#df_longer$cuanti_palabras_suggest #df_longer$cuanti_palabras_suggest[sapply(length(df_longer$cuanti_palabras_suggest == 0))] #if_else(df_longer$cuanti_palabras_suggest[sapply(length(df_longer$cuanti_palabras_suggest == 0))],
#                                   NA,
#                                            cuanti_palabras_suggest)
df_longer <- df_longer |>
mutate(cuanti_palabras_pre_stem = map(cuanti_palabras_suggest,1))
df_longer$cuanti_palabras_pre_stem[sapply(df_longer$cuanti_palabras_pre_stem, is.null)] <- NA
df_longer <- df_longer |>
mutate(cuanti_palabras_pre_stem = unlist(cuanti_palabras_pre_stem))
# Stemming
# Así como para las stopwords hice un archivo específico ahora hago un
# diccionario que agrega más palabras al original
# Hay que tener cuidado porque "quanteda" pisa a dictionary de "hunspell"
df_longer <- df_longer |>
mutate(cuanti_palabras_stem = hunspell_stem(cuanti_palabras_pre_stem, dict = cuanti_diccionario))
df_longer <- df_longer |>
mutate(cuanti_palabras_stem = map(cuanti_palabras_stem,1))
df_longer$cuanti_palabras_stem[sapply(df_longer$cuanti_palabras_stem, is.null)] <- NA
df_longer <- df_longer |>
mutate(cuanti_palabras_stem = unlist(cuanti_palabras_stem))
# Arreglo a mano algunos pequeños casos
df_longer <-  df_longer |>
mutate(
cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, "métodos", "método"),
cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, "cantidades", "cantidad"),
cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, "estadísticas", "estadística"),
cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, "encuestas", "encuesta"),
cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, "técnicas", "técnica"),
cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, "porcentajes", "porcentaje"),
cuanti_palabras_pre_stem = str_replace(cuanti_palabras_pre_stem, "cuentas", "contar"))
#cuanti_palabras_ok = stringi::stri_trans_general(cuanti_palabras_ok, "Latin-ASCII")), # Saco los acentos
#df_longer <- df_longer |>
#mutate(
#cuanti_palabras_hunspell = hunspell_stem(cuanti_palabras_ok, dict = cuanti_diccionario))
#cuanti_palabras_snowballc = wordStem(cuanti_palabras, language = "spanish"))
#cuanti_palabras_hunspell_check = hunspell_check(cuanti_palabras, dict = dictionary("es_ES")),
#| echo: false
#| output: true
library(dplyr)
library(gt)
conteo_palabras_general <- df_longer |>
filter(!is.na(cuanti_palabras_pre_stem)) |>
count(cuanti_palabras_pre_stem) |>
arrange(desc(n)) |>
filter(n > 1) |>
mutate(Porcentaje = n/sum(n))
gt_palabras <- conteo_palabras_general |>
gt() |>
tab_header(title = "Frecuencia y porcentajes de palabras") |>
cols_label(cuanti_palabras_pre_stem = "Palabra",
n = "Cantidad") |>
fmt_percent(columns = Porcentaje)
gt_palabras
#| echo: false
#| output: true
library(ggplot2)
grafico_conteo <- conteo_palabras_general |>
mutate(cuanti_palabras_pre_stem = fct_reorder(cuanti_palabras_pre_stem, n)) |>
ggplot(aes(cuanti_palabras_pre_stem, Porcentaje)) +
geom_col() +
labs(x = "Palabras") +
scale_y_continuous(labels = scales::percent) +
coord_flip()
grafico_conteo
#| echo: false
#| output: true
library(ggwordcloud)
nube_palabras <- ggplot(conteo_palabras_general,
aes(label = cuanti_palabras_pre_stem,
size = n,
color = n)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(max_size = 20) +
labs(title = "Nube de palabras") +
theme(plot.title = element_text(hjust = 0.5))
nube_palabras
#| echo: false
#| output: true
# Es más cómodo "ensanchar" la base luego del análisis para facilitar la tabla
conteo_palabras_grupo <- df_longer |>
filter(!is.na(cuanti_palabras_pre_stem)) |>
group_by(unaj_n_materias_aprobadas_15) |>
count(cuanti_palabras_pre_stem) |>
arrange(desc(n)) |>
filter(n > 1) |>
mutate(Porcentaje = n/sum(n)) |>
select(!n) |>
pivot_wider(names_from = unaj_n_materias_aprobadas_15,
values_from = Porcentaje)
gt_palabras_grupo <- conteo_palabras_grupo |>
gt() |>
tab_header(title = "Frecuencia y porcentajes de palabras según cantidad de materias aprobadas") |>
cols_label(cuanti_palabras_pre_stem = "Palabra") |>
tab_spanner(
label = "Cantidad de materias aprobadas",
columns = c("Hasta 15", "Más de 15")) |>
fmt_percent(columns = c("Hasta 15", "Más de 15"))
#| echo: false
#| output: true
# Es más cómodo "ensanchar" la base luego del análisis para facilitar la tabla
conteo_palabras_grupo <- df_longer |>
filter(!is.na(cuanti_palabras_pre_stem)) |>
group_by(unaj_n_materias_aprobadas_15) |>
count(cuanti_palabras_pre_stem) |>
arrange(desc(n)) |>
filter(n > 1) |>
mutate(Porcentaje = n/sum(n)) |>
select(!n) |>
pivot_wider(names_from = unaj_n_materias_aprobadas_15,
values_from = Porcentaje)
gt_palabras_grupo <- conteo_palabras_grupo |>
gt() |>
tab_header(title = "Frecuencia y porcentajes de palabras según cantidad de materias aprobadas") |>
cols_label(cuanti_palabras_pre_stem = "Palabra") |>
tab_spanner(
label = "Cantidad de materias aprobadas",
columns = c("Hasta 15", "Más de 15")) |>
fmt_percent(columns = c("Hasta 15", "Más de 15"))
View(conteo_palabras_grupo)
gt_palabras_grupo <- conteo_palabras_grupo |>
gt() |>
tab_header(title = "Frecuencia y porcentajes de palabras según cantidad de materias aprobadas") |>
cols_label(cuanti_palabras_pre_stem = "Palabra") |>
tab_spanner(
label = "Cantidad de materias aprobadas",
columns = c("Hasta 15", "Más de 15")) |>
fmt_percent(columns = c("Hasta 15", "Más de 15"))
#| echo: false
#| output: true
library(ggwordcloud)
nube_palabras <- ggplot(conteo_palabras_general,
aes(label = cuanti_palabras_pre_stem,
size = n,
color = n)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(max_size = 20) +
labs(title = "Nube de palabras") +
theme(plot.title = element_text(hjust = 0.5))
nube_palabras
#| echo: false
#| output: true
# Es más cómodo "ensanchar" la base luego del análisis para facilitar la tabla
conteo_palabras_grupo <- df_longer |>
filter(!is.na(cuanti_palabras_pre_stem)) |>
group_by(unaj_n_materias_aprobadas_15) |>
count(cuanti_palabras_pre_stem) |>
arrange(desc(n)) |>
filter(n > 1) |>
mutate(Porcentaje = n/sum(n)) |>
select(!n) |>
pivot_wider(names_from = unaj_n_materias_aprobadas_15,
values_from = Porcentaje)
gt_palabras_grupo <- conteo_palabras_grupo |>
gt() |>
tab_header(title = "Frecuencia y porcentajes de palabras según cantidad de materias aprobadas") |>
cols_label(cuanti_palabras_pre_stem = "Palabra") |>
tab_spanner(
label = "Cantidad de materias aprobadas",
columns = c("Hasta 15", "Más de 15")) |>
fmt_percent(columns = c("Hasta 15", "Más de 15"))
View(conteo_palabras_grupo)
View(conteo_palabras_grupo)
View(conteo_palabras_grupo)
#| echo: false
#| output: true
# Es más cómodo "ensanchar" la base luego del análisis para facilitar la tabla
conteo_palabras_grupo <- df_longer |>
filter(!is.na(cuanti_palabras_pre_stem)) |>
group_by(unaj_n_materias_aprobadas_15) |>
count(cuanti_palabras_pre_stem) |>
arrange(desc(n)) |>
filter(n > 1) |>
mutate(Porcentaje = n/sum(n)) |>
select(!n) |>
pivot_wider(names_from = unaj_n_materias_aprobadas_15,
values_from = Porcentaje)
gt_palabras_grupo <- conteo_palabras_grupo |>
gt() |>
tab_header(title = "Frecuencia y porcentajes de palabras según cantidad de materias aprobadas") |>
cols_label(cuanti_palabras_pre_stem = "Palabra") |>
tab_spanner(
label = "Cantidad de materias aprobadas",
columns = c("Hasta 15", "Más de 15")) |>
fmt_percent(columns = c("Hasta 15", "Más de 15"))
#| echo: false
#| output: true
conteo_palabras_grupo <- df_longer |>
filter(!is.na(cuanti_palabras_pre_stem)) |>
group_by(unaj_n_materias_aprobadas_15) |>
count(cuanti_palabras_pre_stem) |>
arrange(desc(n)) |>
filter(n > 1) |>
mutate(Porcentaje = n/sum(n))
nube_palabras_grupo <- ggplot(conteo_palabras_grupo,
aes(label = cuanti_palabras_pre_stem,
size = n,
color = n)) +
geom_text_wordcloud(area_corr = TRUE) +
scale_size_area(max_size = 10) +
labs(title = "Nube de palabra según cantidad de materias aprobadas") +
theme(plot.title = element_text(hjust = 0.5)) +
facet_wrap(~unaj_n_materias_aprobadas_15)
nube_palabras_grupo
#| output: true
grafo_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = intermediacion)) +
geom_node_point(aes(size = pagerank, colour = pagerank)) +
scale_color_continuous(guide = 'legend') +
theme_graph()
grafo_diego
ggsave(here("Outputs", "grafo_diego.png"))
# En este link hay varias buenas opciones de gráficos
# http://users.dimi.uniud.it/~massimo.franceschet/ns/syllabus/make/tidygraph/tidygraph.html
#| echo: false
#| output: true
nodos <- red_diego |>
activate(nodes) |>
as_tibble()
#| echo: false
#| output: true
comunidad_diego <- ggraph(red_diego, layout = "kk") +
geom_edge_link(aes(alpha = stat(index)), show.legend = FALSE) +
geom_node_point(aes(colour = comunidad), size = 5) +
geom_node_text(aes(label = siglas), repel = TRUE)
theme_graph(foreground = 'steelblue',
fg_text_colour = 'white',
base_family = 'Helvetica')
comunidad_diego
